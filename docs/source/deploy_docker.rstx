===============
DaCHS on Docker
===============

:Author: Carlos Brandt
:Email: carloshenriquebrandt@gmail.com
:Date: |date|


.. contents::
  :depth: 3
  :backlinks: entry
  :class: toc


The goal of this document is to expose how Docker can serve Dachs.
We will explore Dachs and Docker architectures to see if/where they fit.

If you just want to use the current DaCHS container, go straight to
`the image repository <https://hub.docker.com/r/chbrandt/dachs/>`_.
The README file there should be clear enough to put you running
DaCHS-on-Docker (if not, complain).

The first reason to port DaCHS to Docker had tests in mind: in a few
seconds you'd have a fresh, clean DaCHS setup, do your tests -- a new,
clean system would be available, for any other test, just by running
a new docker instance.
Another big reason to explore the use of Docker is because of data
persistence, the use of docker data volumes enables data to thrive
after containers are shutdown or even after a (docker) daemon failure.


Rationale
=========

DaCHS is composed by two living blocks: (1) the data access interface
consulting and (2) a PostgreSQL database.
The so called Dachs server is responsible for providing the interface
between the user and datasets, Postgres stores the data tables.
Of our particular interest here is where data is saved within the
filesystem directories tree: one of our goals in using Docker is to
ease data persistence when Dachs or the O.S. goes on maintenance.

Dachs-server keeps its data under (``$GAVOROOT``) ``/var/gavo`` (and a
config file at ``/etc/gavo.rc``).
Postgres stores its data in its "data_directory", typically at
``/var/lib/postgresql/PG_VERSION/main/``.

In practice, we want to have *data* and *daemons* (physically) detached
from each other; Using Docker *jargon*, we want data to be stored in
*data volumes* while daemons go in usual *containers*.

Here goes a sketch of our current model::

  +==========================================================+
  | Dachs-on-Docker                                          |
  |                                                          |
  |  +-------------------+     +--------------------------+  |
  |  | Dachs             |     | Postgres                 |  |
  |  |                   |     |                          |  |
  |  |  .............    |     |  ....................    |  |
  |  |  |           |    |     |  |                  |    |  |
  |  |  | $GAVOROOT |    |     |  | "data_directory" |    |  |
  |  +-/             \---+     +-/                    \---+  |
  +===/               \=========/                      \=====+
      |               '         '                      |
      |                                                |
      |    HOST FILESYSTEM: persistent data volumes    |
      |                                                |
      |................................................|



Files structure
---------------

The files under ``GAVOROOT`` are organized as follows:

.. code::

  /var/gavo
  +---cache
  +---etc
  |   +---defaultmeta.txt
  |   +---userconfig.rd
  |   +---...
  +---inputs
  |   +-- DATASET_1
  |   |   +---data
  |   |   +---q.rd
  |   +-- DATASET_2
  |       +---data
  |       +---q.rd
  +---logs
  +---state
  +---tmp
  +---web
      +---templates
          +---root.html

where ``DATASET_1`` and ``DATASET_2`` are hypothetical datasets.
(Lots of files have been omitted in this example files tree, which is
meant to highlight the basic structure.)


Dockerizing
===========

The current implementation uses docker-compose to orchestrate both
containers and the data volumes.

Take a look at:

 https://hub.docker.com/r/chbrandt/dachs/

for the current available images and documentation.

We proceed here with a more manual procedure to emphasize the steps
necessary, to be called *old style*.


Old Style
=========

The server
----------

The (main) container encapsulates the Dachs server itself, files and
directories to run the software.


Ingesting data
--------------

Before getting into the servers, it is worth highlighting the steps
we need to have a data available to dachs so that it can then publish.

First, we have to place the data and their descriptor (``RD``) in some
directory -- for instance, ``DATASET_1/``.

To ingest the data, ``gavo``/dachs server has to be running, as well as
``postgresql``.

And then we can ``gavo import DATASET_1/q``.

Picture the components::

                     +-------------+          +------------+
                     | gavo daemon |   ----   | postgresql |
                     +-------------+          +------------+
                      |                        |
  +...........+       |                        |
  |  DATASET  |  -----+----  gavo import  -----`.
  +...........+              ```````````        |
                                                |
                                                |
                                                `===============
                                                 | data access |
                                                 |  interface  |
                                                 ===============


It is important to have this diagram in mind to understand not only the
components but the steps to make data available for Docker each
container can run only one process (ideally).


Dockerizing
===========

A first try on dockerizing DaCHS can be taken from the `Docker hub`_
(the respective Dockerfile is linked from there).  There you have dachs
and postgres servers running all together -- the ``latest`` image --,
but also the option for dachs and postgres running individually (see
section `Splitting dachs/postgres`_).

Next step is to plug-in data volumes; to have data added from the
outside world -- take ``DATASET_1`` and ``DATASET_2`` as examples.


Data Volumes
------------

Attaching a volume to a container is a simple process,
we just have to follow some rules to make good use of it.

First of all, volumes can be attached to a container *only* at the
moment the container is initialized; volumes *cannot* be mounted on
already running containers.
Second, volumes are made to persist; this means that volumes will still
exist even after the container removal.
It is up to the user to manually remove data volumes.

To create a data volume, we basically initialize a container with no
action, but a volume::

 $ docker create --name dataset_1 \
                 -v $PWD/DATASET_1:/var/gavo/inputs/dataset_1 \
                 ubuntu /bin/true

The line above supposes the directory ``DATASET_1`` is under our current
directory. The volume created has ``/var/gavo/inputs/dataset_1`` mapping
to host's ``$PWD/DATASET_1``. (The image ``ubuntu`` is used without
particular reason; **any** image should do the job.)

Now, another container can have access to the very same volume(s)
mounted in ``dataset_1`` through ``docker run``'s option
``--volumes-from``; without further arguments, the vary same mounting
points will be replicated.

In our current sandbox, a line like the following is to work::

 $ docker run -it --name server \
                  --volumes-from dataset_1 \
                  -p 8080:80
                  chbrandt/dachs:allinone

After that, you should find yourself inside server's shell. The next
steps are the usual ones to publish ``dataset_1``, we just have to put
things up-and-running before::

 $ service postgresql start
 $ gavo serve start
 $ gavo import dataset_1/q

Now gavo/DaCHS should be accessible from the host (localhost) at port ``8080``.


Splitting dachs/postgres
------------------------

To make a proper, or better use of containers capacities, dachs (server)
and postgres should be separated; each one to run in its own container.
And then ``dachs`` access ``postgres`` through (tcp) network.

Since the Debian package provided -- ``gavodachs-server`` -- provides
a complete setup solution in what regards both PostgreSQL and DaCHS
servers, the idea to have them on their own containers was/is to make
use of the Debian-apt solution and modify the environment as needed
on each image.

The modifications, that can be seen through their (public) dockerfiles
are here listed:

* dachs_
   * the server looks for a host called "postgres" at the same network;
     this is accomplished by changing ``/var/gavo/etc/dsn`` "host" entry,
     addition of corresponding line in ``/etc/hosts`` (automatically)
     added by Docker when using the ``--link postgres`` option (see below)
     and by ``gavo init host=postgres``
* postgres_
   * PSQL trusts on every host from the (Docker) network 172.17.0.0/24;
     this is accomplished by modifying the corresponding ``pg_hba.conf``

Clearly, a downside of dachs' customization is the forced name for
``postgres``' container.

Apart from that, the ``postgres`` exposes (default) port ``5432``.
The other container, ``dachs`` exposes the port ``8080``.

The way ``dachs`` container knows about ``postgres`` is through the use
of ``--link`` option, for when used this option receives the *name* of
the linked container (for instance, ``postgres``) the exposed ports are
automatically recognized by the calling container.
For more details, please take a look at the official documentation[1]_.

To have them running -- the servers alone -- one should go like::

$ docker run -dt --name postgres chbrandt/dachs:postgres
$ docker run -it --link postgres chbrandt/dachs:server

Sure we want to add other options to ``dachs:server``:

* to map port 8080: ``-p 8080:8080``
* to mount data volumes, for ``gavo import`` one/some RDs

For a first try, and example data/RD is available as ``chbrandt/dachs:data``.
Have a look at `Docker hub`_ description for complete command lines.

Complain if something is not clear.



.. _chbrandt/dachs: `Docker hub`_
.. _Docker hub: https://hub.docker.com/r/chbrandt/dachs/

.. _dachs: https://github.com/chbrandt/docker-dachs/tree/dachs/dockerfile
.. _postgres: https://github.com/chbrandt/docker-dachs/tree/postgres/dockerfile

.. [1] https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/
.. |date| date::
